---
- name: PAN-OS HA OS Downgrade with Config Backup
  hosts: "{{ hosts | default('PA-HA') }}"
  connection: local
  gather_facts: false

  vars:
    device:
      ip_address: "{{ ip_address }}"
      username: "{{ username }}"
      password: "{{ password }}"

    backup_directory: "{{ lookup('env', 'PANOS_BACKUP_DIR') | default('/runner/backups', true) }}"
    backup_filename: "{{ backup_directory }}/{{ inventory_hostname | default('pa-fw') }}-running-config.xml"

    reboot_between_steps: true
    quiet_polling: true

  collections:
    - paloaltonetworks.panos

  tasks:
    - name: Validate downgrade_path is provided
      ansible.builtin.assert:
        that:
          - downgrade_path is defined
          - downgrade_path | length > 0
        fail_msg: "You must provide -e downgrade_path='[\"10.2.3\",\"10.2.2\"]'"
      run_once: true

    - name: Gather HA and system facts
      paloaltonetworks.panos.panos_facts:
        provider: "{{ device }}"
        gather_subset: ["system", "ha"]
      register: ha_facts

    - name: Gather full HA configuration (running config)
      paloaltonetworks.panos.panos_facts:
        provider: "{{ device }}"
        gather_subset: ["config"]
      register: ha_cfg

    - name: Record HA snapshot for {{ inventory_hostname }}
      ansible.builtin.set_fact:
        ha_runtime:
          inventory_hostname: "{{ inventory_hostname }}"
          hostname: "{{ ha_facts.ansible_facts.ansible_net_hostname }}"
          serial: "{{ ha_facts.ansible_facts.ansible_net_serialnum | default('unknown') }}"
          sw_version: "{{ ha_facts.ansible_facts.ansible_net_version | default('unknown') }}"
          ha_enabled: "{{ (ha_facts.ansible_facts.ansible_net_ha_enabled | default(false)) | bool }}"
          ha_mode: "{{ (ha_facts.ansible_facts.ansible_net_ha_localmode | default('unknown')) | lower }}"
          ha_initial_role: "{{ (ha_facts.ansible_facts.ansible_net_ha_localstate | default('unknown')) | lower }}"
          ha_group_id: "{{ ha_facts.ansible_facts.ansible_net_ha_group_id | default('1') }}"

    - name: Discover HA interface wiring from running config
      ansible.builtin.set_fact:
        ha1_ip_address: >-
          {{ (ha_cfg.ansible_facts.ansible_net_config
              | regex_search('(?s)<interface>.*?<ha1>.*?<ip-address>([^<]+)</ip-address>', '\1')
              | default([]))
             | first | default('') }}
        ha1_netmask: >-
          {{ (ha_cfg.ansible_facts.ansible_net_config
              | regex_search('(?s)<interface>.*?<ha1>.*?<netmask>([^<]+)</netmask>', '\1')
              | default([]))
             | first | default('') }}
        ha1_port: >-
          {{ (ha_cfg.ansible_facts.ansible_net_config
              | regex_search('(?s)<interface>.*?<ha1>.*?<port>([^<]+)</port>', '\1')
              | default([]))
             | first | default('') }}
        ha_peer_ip: >-
          {{ (ha_cfg.ansible_facts.ansible_net_config
              | regex_search('(?s)<high-availability>.*?<group>.*?<peer-ip>([^<]+)</peer-ip>', '\1')
              | default([]))
             | first | default('') }}

    - name: Validate discovered HA wiring
      ansible.builtin.assert:
        that:
          - ha1_ip_address | length > 0
          - ha1_netmask | length > 0
          - ha1_port | length > 0
          - ha_peer_ip | length > 0
        fail_msg: >-
          Failed to auto-discover HA1/HA2/peer wiring from running config.
          Verify high-availability is configured under deviceconfig on each firewall.

    - name: Consolidate HA topology view
      run_once: true
      delegate_to: localhost
      delegate_facts: true
      vars:
        ha_view: "{{ ansible_play_hosts_all | map('extract', hostvars, 'ha_runtime') | list }}"
      block:
        - name: Validate HA pair is active/passive and healthy
          ansible.builtin.assert:
            that:
              - ha_view | length == 2
              - (ha_view | map(attribute='ha_enabled') | min)
              - (ha_view | map(attribute='ha_mode') | unique) == ['active-passive']
              - (ha_view | selectattr('ha_initial_role', 'equalto', 'active') | list | length) == 1
              - (ha_view | selectattr('ha_initial_role', 'equalto', 'passive') | list | length) == 1
            fail_msg: "Playbook currently supports exactly two nodes in active/passive HA."
        - name: Persist HA role ownership
          ansible.builtin.set_fact:
            ha_topology: "{{ ha_view }}"
            ha_active_host: "{{ (ha_view | selectattr('ha_initial_role', 'equalto', 'active') | first).inventory_hostname }}"
            ha_passive_host: "{{ (ha_view | selectattr('ha_initial_role', 'equalto', 'passive') | first).inventory_hostname }}"

    - name: Short-circuit when downgrade path does not reduce PAN-OS version
      run_once: true
      vars:
        ha_topology_view: "{{ hostvars['localhost'].ha_topology | default([]) }}"
      ansible.builtin.assert:
        that:
          - "(downgrade_path | select('version', item.sw_version | default('0.0.0'), '>=') | list | length) == 0"
        fail_msg: >-
          Short-circuiting downgrade: host {{ item.hostname | default(item.inventory_hostname) }} ({{ item.inventory_hostname }})
          runs PAN-OS {{ item.sw_version | default('unknown') }}, and requested downgrade_path entries
          {{ downgrade_path | select('version', item.sw_version | default('0.0.0'), '>=') | list }} are not lower.
          Ensure all downgrade_path versions are strictly lower than the current PAN-OS version before rerunning.
      loop: "{{ ha_topology_view }}"
      loop_control:
        label: "{{ item.inventory_hostname }}"

    - name: Mark initial HA role flags
      ansible.builtin.set_fact:
        is_initial_active: "{{ ha_runtime.ha_initial_role == 'active' }}"
        is_initial_passive: "{{ ha_runtime.ha_initial_role == 'passive' }}"

    - name: Backup running configuration
      paloaltonetworks.panos.panos_export:
        provider: "{{ device }}"
        category: configuration
        filename: "{{ backup_filename }}"
        create_directory: true

    - name: Disable config sync
      paloaltonetworks.panos.panos_type_cmd:
        provider: "{{ device }}"
        cmd: set
        xpath: "/config/devices/entry[@name='localhost.localdomain']/deviceconfig/high-availability/group/configuration-synchronization"
        element: "<enabled>no</enabled>"

    - name: Commit HA change (config sync disabled)
      paloaltonetworks.panos.panos_commit_firewall:
        provider: "{{ device }}"
        description: "Disable HA config sync before OS downgrade"

    - name: Re-collect HA facts after disabling config sync
      paloaltonetworks.panos.panos_facts:
        provider: "{{ device }}"
        gather_subset: ["ha"]
      register: ha_post_disable

    - name: Verify HA state after disabling config sync
      ansible.builtin.assert:
        that:
          - ha_post_disable.ansible_facts.ansible_net_ha_enabled | bool
          - (ha_post_disable.ansible_facts.ansible_net_ha_localmode | lower) == 'active-passive'
          - ha_post_disable.ansible_facts.ansible_net_ha_localstate | lower in ['active', 'passive']
        fail_msg: "Unexpected HA state after disabling config sync; check HA configuration on device."

    - name: Orchestrate passive-first downgrade sequence (controller-driven)
      run_once: true
      vars:
        passive_host: "{{ hostvars['localhost'].ha_passive_host }}"
        active_host: "{{ hostvars['localhost'].ha_active_host }}"
      block:
        - name: Wait for any running commit to finish on passive
          paloaltonetworks.panos.panos_op:
            provider:
              ip_address: "{{ hostvars[passive_host].ip_address }}"
              username: "{{ hostvars[passive_host].username }}"
              password: "{{ hostvars[passive_host].password }}"
            cmd: "<show><jobs><all></all></jobs></show>"
            cmd_is_xml: true
          register: passive_jobs
          until: passive_jobs.stdout_xml is not search('<type>Commit</type>.*?<status>(PEND|ACT|RUN|ACTIVE)</status>')
          retries: 120
          delay: 5

        - name: Downgrade passive firewall first
          ansible.builtin.include_tasks: tasks/upgrade_step_v2.yml
          loop: "{{ downgrade_path }}"
          loop_control:
            label: "{{ item }}"
          vars:
            version_item: "{{ item }}"
            device:
              ip_address: "{{ hostvars[passive_host].ip_address }}"
              username: "{{ hostvars[passive_host].username }}"
              password: "{{ hostvars[passive_host].password }}"

        - name: Suspend original active to trigger failover
          paloaltonetworks.panos.panos_op:
            provider:
              ip_address: "{{ hostvars[active_host].ip_address }}"
              username: "{{ hostvars[active_host].username }}"
              password: "{{ hostvars[active_host].password }}"
            cmd: "request high-availability state suspend"

        - name: Wait until downgraded passive becomes active and ready
          block:
            - name: Check HA role on downgraded passive
              paloaltonetworks.panos.panos_facts:
                provider:
                  ip_address: "{{ hostvars[passive_host].ip_address }}"
                  username: "{{ hostvars[passive_host].username }}"
                  password: "{{ hostvars[passive_host].password }}"
                gather_subset: ["ha"]
              register: passive_ha_after_failover
              until: (passive_ha_after_failover.ansible_facts.ansible_net_ha_localstate | lower) == 'active'
              retries: 40
              delay: 15

            - name: Wait for downgraded passive (now active) readiness
              paloaltonetworks.panos.panos_check:
                provider:
                  ip_address: "{{ hostvars[passive_host].ip_address }}"
                  username: "{{ hostvars[passive_host].username }}"
                  password: "{{ hostvars[passive_host].password }}"
              register: passive_ready_as_active
              until: passive_ready_as_active is not failed and passive_ready_as_active.msg == 'Device is ready.'
              retries: 60
              delay: 15

        - name: Wait for any running commit to finish on original active
          paloaltonetworks.panos.panos_op:
            provider:
              ip_address: "{{ hostvars[active_host].ip_address }}"
              username: "{{ hostvars[active_host].username }}"
              password: "{{ hostvars[active_host].password }}"
            cmd: "<show><jobs><all></jobs></show>"
            cmd_is_xml: true
          register: active_jobs
          until: active_jobs.stdout_xml is not search('<type>Commit</type>.*?<status>(PEND|ACT|RUN|ACTIVE)</status>')
          retries: 120
          delay: 5

        - name: Downgrade originally active firewall
          ansible.builtin.include_tasks: tasks/upgrade_step_v2.yml
          loop: "{{ downgrade_path }}"
          loop_control:
            label: "{{ item }}"
          vars:
            version_item: "{{ item }}"
            device:
              ip_address: "{{ hostvars[active_host].ip_address }}"
              username: "{{ hostvars[active_host].username }}"
              password: "{{ hostvars[active_host].password }}"

        - name: Return suspended firewall to functional state
          paloaltonetworks.panos.panos_op:
            provider:
              ip_address: "{{ hostvars[active_host].ip_address }}"
              username: "{{ hostvars[active_host].username }}"
              password: "{{ hostvars[active_host].password }}"
            cmd: "request high-availability state functional"

    - name: Re-enable config sync
      paloaltonetworks.panos.panos_type_cmd:
        provider: "{{ device }}"
        cmd: set
        xpath: "/config/devices/entry[@name='localhost.localdomain']/deviceconfig/high-availability/group/configuration-synchronization"
        element: "<enabled>yes</enabled>"

    - name: Commit HA change (config sync enabled)
      paloaltonetworks.panos.panos_commit_firewall:
        provider: "{{ device }}"
        description: "Re-enable HA config sync after OS downgrade"

    - name: Force running-config sync from initial active back to peer
      paloaltonetworks.panos.panos_op:
        provider: "{{ device }}"
        cmd: "request high-availability sync-to-remote running-config"
      when: inventory_hostname == hostvars['localhost'].ha_active_host

    - name: Ensure original active regains active role if needed
      run_once: true
      vars:
        original_active: "{{ hostvars['localhost'].ha_active_host }}"
        original_passive: "{{ hostvars['localhost'].ha_passive_host }}"
      block:
        - name: Check current HA roles after downgrades
          paloaltonetworks.panos.panos_facts:
            provider:
              ip_address: "{{ hostvars[item].ip_address }}"
              username: "{{ hostvars[item].username }}"
              password: "{{ hostvars[item].password }}"
            gather_subset: ["ha"]
          loop: "{{ [original_active, original_passive] }}"
          register: final_ha_view

        - name: Derive current active host after downgrades
          ansible.builtin.set_fact:
            current_active_host: >-
              {{ (final_ha_view.results
                    | selectattr('ansible_facts.ansible_net_ha_localstate', 'defined')
                    | selectattr('ansible_facts.ansible_net_ha_localstate', 'equalto', 'active')
                    | map(attribute='item') | list | first | default('')) }}

        - name: Suspend current active to fail back to original active
          paloaltonetworks.panos.panos_op:
            provider:
              ip_address: "{{ hostvars[current_active_host].ip_address }}"
              username: "{{ hostvars[current_active_host].username }}"
              password: "{{ hostvars[current_active_host].password }}"
            cmd: "request high-availability state suspend"
          when:
            - current_active_host is defined
            - current_active_host | length > 0
            - current_active_host != original_active

        - name: Wait for original active to become active again after failback
          paloaltonetworks.panos.panos_facts:
            provider:
              ip_address: "{{ hostvars[original_active].ip_address }}"
              username: "{{ hostvars[original_active].username }}"
              password: "{{ hostvars[original_active].password }}"
            gather_subset: ["ha"]
          register: final_active_after_failback
          until: (final_active_after_failback.ansible_facts.ansible_net_ha_localstate | lower) == 'active'
          retries: 40
          delay: 30
          when:
            - current_active_host is defined
            - current_active_host | length > 0
            - current_active_host != original_active

        - name: Return suspended firewall to functional state after failback
          paloaltonetworks.panos.panos_op:
            provider:
              ip_address: "{{ hostvars[current_active_host].ip_address }}"
              username: "{{ hostvars[current_active_host].username }}"
              password: "{{ hostvars[current_active_host].password }}"
            cmd: "request high-availability state functional"
          when:
            - current_active_host is defined
            - current_active_host | length > 0
            - current_active_host != original_active

    - name: Wait for original active role to return
      paloaltonetworks.panos.panos_facts:
        provider: "{{ device }}"
        gather_subset: ["ha"]
      register: final_active_state
      until: (final_active_state.ansible_facts.ansible_net_ha_localstate | lower) == 'active'
      retries: 40
      delay: 30
      when: is_initial_active

    - name: Wait for original passive role to return
      paloaltonetworks.panos.panos_facts:
        provider: "{{ device }}"
        gather_subset: ["ha"]
      register: final_passive_state
      until: (final_passive_state.ansible_facts.ansible_net_ha_localstate | lower) == 'passive'
      retries: 40
      delay: 30
      when: is_initial_passive

    - name: Report HA downgrade result
      run_once: true
      ansible.builtin.debug:
        msg: |
          HA downgrade complete. Original active host ({{ hostvars['localhost'].ha_active_host }}) is active again and
          original passive host ({{ hostvars['localhost'].ha_passive_host }}) returned to passive. Backups saved under {{ backup_directory }}.

